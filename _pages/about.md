---
permalink: /
title: ""
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

## About me

I'm a 4th-year PhD student at the Computer Science department of UC Riverside, where I'm fortunate to be advised by Prof. [Nael Abu-Ghazaleh](https://www.cs.ucr.edu/~nael/) and Prof. [Yue Dong](https://yuedong.us/). 

<!-- My research focuses on Exploring Generative AI & Trustworthiness; particularly studying (Multimodal) Large Language Model Agents (MLLMs & LLMs) with an emphasis on Safety, Alignment, Ethics, Security/Privacy, Bias/Fairness and Sociotechnical challenges. Iâ€™m also interested in studying AI agents in interactive scenarios (e.g., Mixed Reality (AR/VR), Robotics and Embodied AI) to enhance Human-AI Interaction and improve anomaly detection. -->

<!-- My research lies at the intersection of Generative AI and trustworthiness, particularly focusing on Multi-Modal Large Language Models (LLMs & MLLMs) with an emphasis on Safety, Alignment, Adversarial Robustness, Ethics, Bias, Fairness, Sociotechnical challenges, and Security/Privacy. Additionally, I am deeply interested in advancing Multimodal Understanding, Reasoning, and Retrieval, as well as Expert Specialization, Personalization, Multilingual MLLMs, and AI Agent development. My work also involves exploring Evaluation methods and Reward Modeling to ensure more adaptive, steerable, and contextually aligned AI systems. I have been also working on integrating AR/VR and Mixed Reality (MR) with AI Agents. -->

<!-- My research focuses on the intersection of Generative AI and trustworthiness, particularly on Multi-Modal Language Models (LLMs/MLLMs) and agents with an emphasis on Safety, Alignment, Robustness, Ethics, Fairness, and Privacy. Iâ€™m also passionate about advancing Multimodal Reasoning, understanding, Expert Specialization, Multilingual MLLMs, and Evaluation/Reward Modeling for adaptive, steerable systems. I have been also working on integrating AR/VR and Mixed Reality (MR) with AI Agents. -->

My research focuses on the intersection of Generative AI and trustworthiness, particularly on Multimodal Language Models (LLMs/MLLMs) and AI Agents such as Computer-Use Agents (CUAs) with an emphasis on Alignment, Robustness, Safety, Ethics, Fairness, Bias, and Security/Privacy. Additionally, Iâ€™m deeply interested in advancing Multimodal Understanding, Reasoning, and Retrieval, as well as Expert Specialization, Personalization, Multilingual MLLMs. My work also involves exploring novel Evaluation methods, Reward Modeling, and Post-Training Algorithms (e.g., Machine Unlearning, Reinforcement Learning-based, etc.) for adaptive, steerable, and contextually aligned AI agents. I have been also working on integrating AR/VR and Mixed Reality (MR) with AI Agents.

I'll be direct: the Dark Side of AI ğŸ˜ˆ has always captivated me. I enjoy probing models from an adversarial perspective (Dopamine Rush ğŸŒŠğŸ§¨), because exposing alignment gaps is the fastest path to building safer, more robust systems.

In Summer 2025, I rejoined Microsoft <img src="images/MSR.png" width="20" height="20"> as a Research Intern with the AI Frontiers and AI Red Team, working with [Besmira Nushi](https://besmiranushi.com/), [Roman Lutz](https://romanlutz.github.io/), and [Vibhav Vineet](https://vibhav-vineet.github.io/) on the Safety and Trustworthiness of Computer-Use Agents (CUAs), introducing the "Blind Goal-Directedness" phenomenon.   

In Summer 2024, I also had an incredible experience as a Research Intern at [Microsoft Research](https://www.microsoft.com/en-us/research/) <img src="images/MSR.png" width="20" height="20">, working with [Javier Hernandez](http://javierhr.com/) and [Jina Suh](https://www.microsoft.com/en-us/research/people/jinsuh/). There, I had to pause my adversarial mindset and be the â€œgood guyâ€ ğŸ˜ˆâ†’ğŸ˜‡; developing evaluation methods to measure empathy and user satisfaction in LLM chatbots, and training context-specific expert adapters to dynamically steer empathy based on user needs.


<!-- Here you can find my [CV](https://drive.google.com/file/d/1Ifl76axYbNrwn3AmkGRNLfZGqTpd2eEt/view?usp=share_link). -->

<!-- I never limit myself, enjoying the pursuit of interdisciplinary research, and I'm enthusiastic about exploring innovative concepts. Let's collaborate ğŸ˜„ -->

<!-- <span style="font-weight:700;font-size:14px;color:red">I'm actively looking for Summer2024 Research Internship roles in ML/LLM/VLMs and would appreciate any interesting opportunities!</span> -->




<!-- This is the front page of a website that is powered by the [academicpages template](https://github.com/academicpages/academicpages.github.io) and hosted on GitHub pages. [GitHub pages](https://pages.github.com) is a free service in which websites are built and hosted from code and data stored in a GitHub repository, automatically updating when a new commit is made to the respository. This template was forked from the [Minimal Mistakes Jekyll Theme](https://mmistakes.github.io/minimal-mistakes/) created by Michael Rose, and then extended to support the kinds of content that academics have: publications, talks, teaching, a portfolio, blog posts, and a dynamically-generated CV. You can fork [this repository](https://github.com/academicpages/academicpages.github.io) right now, modify the configuration and markdown files, add your own PDFs and other content, and have your own site for free, with no ads! An older version of this template powers my own personal website at [stuartgeiger.com](http://stuartgeiger.com), which uses [this Github repository](https://github.com/staeiou/staeiou.github.io). -->


<!-- News! 
------ -->
<!-- ## News!

<span style="font-weight:400;font-size:14px"> Nov 2023: ["Jailbreak in Pieces"](https://arxiv.org/pdf/2307.14539.pdf): Won the <span style="font-weight:700;font-size:14px;color:red">"Best Paper Award"</span> at [SoCal NLP 2023](https://socalnlp.github.io/symp23/index.html#award)!

<span style="font-weight:400;font-size:14px"> Sep 2023: ["Vulnerabilities of Large Language Models to Adversarial Attacks](https://llm-vulnerability.github.io/)" accepted to <span style="font-weight:700;font-size:14px">ACL'24 for a tutorial!</span></span>

<span style="font-weight:400;font-size:14px"> July 2023: I did my own first paper :D, [Plug and Pray: Exploiting off-the-shelf components of Multi-Modal Models](https://arxiv.org/abs/2307.14539), check it out!</span>

<span style="font-weight:400;font-size:14px"> April 2023: I will be serving as the moderator & evaluator of student presentations at [UGRS2023](https://engage.ucr.edu/symposium)!</span>
 -->

News â¬‡ï¸ (Scroll down)
------
<font size="3">
<div style="overflow-y: auto; max-height: 300px; padding-right: 10px; font-size: 15.5px;">
<ul>
	<li>
		<b>September 2025</b>: Wrapped up my Microsoft internship with "Just Do It!? Computer-Use Agents Exhibit Blind Goal-Directedness". Check it out ğŸ‘€! We are also on the top daily papers on HuggingFace ğŸ¤—
		<a href="https://arxiv.org/abs/2510.01670" target="_blank">[ArXiv]</a>
		<a href="https://huggingface.co/papers/date/2025-10-03" target="_blank">[Top Daily Papers ğŸ¤—]</a> 
		<a href="https://www.youtube.com/watch?v=-fiCQNVG4y4" target="_blank">[YouTube]</a>
	</li>
	<li>
		<b>Summer 2025</b>: I will get back to <b>Microsoft Research</b> <img src="images/MSR.png" width="20" height="20"> for my 2nd internship! (Super excited ğŸ’¥ğŸ‘¨ğŸ»â€ğŸ’»!)
	</li>
	<li>
		<b>May 2025</b>: ğŸ–ğŸ”¥ Our paper "Layer-wise Alignment: Examining Safety Alignment Across Image Encoder Layers in Vision Language Models" was accepted for <span style="font-weight:700;font-size:14px;color:red">"Spotlight presentation(top 2.6% of 12,107 submissions)</span> at <b>ICML2025</b>! 
		<a href="https://openreview.net/pdf?id=F1ff8zcjPp" target="_blank">[OpenReview]</a>
		<a href="https://news.ucr.edu/articles/2025/09/04/ucr-researchers-fortify-ai-against-rogue-rewiring" target="_blank">[News]</a>
	</li>
	<li>
		<b>Oct 2024</b>: I will serve as a reviewer for <b>ICLR 2025</b>. 
	</li>
	<li>
		<b>Sep 2024</b>: Our paper (Co-First Authored) on "Textual Unlearning" to solve "Cross-Modality Safety Alignment" was Accepted at <b>EMNLP 2024 Findings</b> - See y'all in Florida ğŸŠğŸŒŠğŸŒ´
		<a href="https://arxiv.org/pdf/2406.02575">[Paper]</a>
	</li>
	<li>
		<b>Sep 2024</b>: I successfully concluded my internship at <b>Microsoft Research</b> <img src="images/MSR.png" width="20" height="20">; The best experience I could imagine and thankful to my whole team! 
		Stay tuned for the research paper and the models (Cooking ... ğŸ‘¨ğŸ»â€ğŸ³ğŸ³ğŸ”¥)
	</li>
	<li>
		<b>Sep 2024</b>: My work was cited in the "International Scientific Report on the Safety of Advanced AI".
		<a href="https://hal.science/hal-04612963/">[Report]</a>
	</li>
	<li>
		<b>Aug 2024</b>: ğŸ‘¨ğŸ»â€ğŸ“ We gave a 3-hour tutorial on "AI Safety and Adversarial Attacks" at <b>ACL 2024</b>.
		<a href="https://llm-vulnerability.github.io/">[Material]</a>
		<a href="https://arxiv.org/abs/2310.10844">[Paper]</a>
	</li>
	<li>
		<b>July 2024</b>: I gave a talk on AI Safety and AR/VR Security with implications on Human-Computer Interaction at MSR <img src="images/MSR.png" width="20" height="20">.
		<a href="https://drive.google.com/file/d/12yGyDXAE_bZ38xdFbJSqoH3F9Lvna2vQ/view?usp=sharing">[Slides]</a>
	</li>
	<li>
		<b>July 2024</b>: I presented my works on "Unlearning" and "Cross-Modality Safety Alignment" at McGill NLP group <img src="images/mila.png" width="45" height="45">.
		<a href="https://mcgill-nlp.github.io/reading-group/summer-2024/erfan-shayegani/">[Site]</a>
	</li>
	<li>
		<b>Summer 2024</b>: I will be doing an internship at <b>Microsoft Research</b> <img src="images/MSR.png" width="20" height="20"> in Summer 2024! (Thrilled ğŸ’¥ğŸ‘¨ğŸ»â€ğŸ’»)
	</li>
	<li>
		<b>June 2024</b>: I'm honored to serve as a reviewer for <b>NextGenAISafety 2024 at ICML</b>!
		<a href="https://icml.cc/virtual/2024/workshop/29944">[ICML2024]</a>
	</li>
	<li>
		<b>June 2024</b>: ğŸ…ğŸ† I won the <span style="font-weight:700;font-size:14px;color:red">"Outstanding Teaching Award"</span> of the CS department of UCR! (Grateful ğŸ¤—) 
		<a href="images/Best_Teaching_CS.jpg" target="_blank">[Award]</a>
	</li>
	<li>
		<b>Mar 2024</b>: My work on Cross-Modal Vulnerability Alignment in Vision-Language Models was accepted for a presentation at <b>SuperAGI Leap Summit 2024</b>! 
		<a href="https://youtu.be/lYNwpJRJU9U?t=2407">[Video]</a>
		<a href="https://superagi.com/agi-leap-summit/">[SuperAGI]</a>
	</li>
	<li>
		<b>Mar 2024</b>: Our paper "That Doesn't Go There: Attacks on Shared State in Multi-User Augmented Reality Applications" has been accepted to <b>USENIX SECURITY 2024</b>! 
		<a href="https://arxiv.org/abs/2308.09146">[paper]</a>
	</li>
	<li>
		<b>Feb 2024</b>: Gave a lightning talk on my AI Safety work at <b>Cohere For AI</b>! 
		<a href="https://docs.google.com/presentation/d/12QSc14ph0gH6TMkoDo-PaLDyoqYokXhf/edit?usp=sharing&ouid=112584313979945870018&rtpof=true&sd=true" target="_blank">[Slides]</a>
	</li>
	<li>
		<b>Jan 2024</b>: ğŸ–ğŸ”¥ Our paper "Jailbreak in Pieces: Compositional Adversarial Attacks on Multi-Modal Language Models" was accepted for <span style="font-weight:700;font-size:14px;color:red">"Spotlight presentation(top 5% of 7262 submissions)</span> at <b>ICLR2024</b>! 
		<a href="https://openreview.net/forum?id=plmBsXHxgR" target="_blank">[OpenReview]</a>
		<a href="https://recorder-v3.slideslive.com/#/share?share=91193&s=cf14f58c-ffdc-48c2-a834-5929ac1e8bc7" target="_blank">[SlidesLive-Video]</a>
		<a href="https://youtu.be/Gg13cyYui_o?t=829" target="_blank">[YoutubeAInews]</a>
	</li>
	<li>
		<b>Nov 2023</b>: ğŸ† Our paper "Jailbreak in Pieces: Compositional Adversarial Attacks on Multi-Modal Language Models" won the <span style="font-weight:700;font-size:14px;color:red">"Best Paper Award"</span> at <b>SoCal NLP 2023</b>!
		<a href="https://arxiv.org/abs/2307.14539" target="_blank">[paper]</a>
    <a href="https://socalnlp.github.io/symp23/index.html#award" target="_blank">[Award]</a>
    <a href="https://news.ucr.edu/articles/2024/01/09/ucr-outs-security-flaw-ai-query-models" target="_blank">[News1]</a>
	<a href="https://www1.cs.ucr.edu/news/2023/11/19/cse-team-won-best-paper-award-socal-nlp-symposium" target="_blank">[News2]</a>
	<a href="https://techxplore.com/news/2024-01-scientists-flaw-ai-query.html" target="_blank">[News3]</a>
	</li>
	<li>
		<b>Sep 2023</b>: Our paper "Vulnerabilities of Large Language Models to Adversarial Attacks" has been accepted for a tutorial to <b>ACL2024</b>! 
		<a href="https://arxiv.org/abs/2310.10844" target="_blank">[paper]</a>
	</li>
	<li>
		<b>Jul 2023</b>: Yay! I did my own first paper :D! "Plug and Pray: Exploiting off-the-shelf components of Multi-Modal Models" 
		<a href="https://arxiv.org/abs/2307.14539v1" target="_blank">[paper]</a>
	</li>
	<li>
		<b>Apr 2023</b>: I will be serving as the moderator & evaluator of student presentations at UGRS2023! 
		<a href="https://engage.ucr.edu/symposium" target="_blank">[paper]</a>
	</li>
</ul>
</div>
</font>

Education
------
<img src="images/ucr.png" width="25" height="25"><span style="font-weight:400;font-size:14px"> Ph.D. in Computer Science at University of California, Riverside (Sep2022-Present)</span>

<img src="images/sharif.svg" width="25" height="25"><span style="font-weight:400;font-size:14px"> B.Sc. in Electrical Engineering at Sharif University of Technology (2017-2022)</span>

<span style="font-weight:400;font-size:13px">Ranked 68th among 150,000 participants in Iran Nationwide University Entrance Exam (Konkur)</span>

<!-- <p style="font-weight:400;font-size:13px">Ranked 68th among 150,000 participants in Iran Nationwide University Entrance Exam (Konkur)</p> -->



<!-- A data-driven personal website
======
Like many other Jekyll-based GitHub Pages templates, academicpages makes you separate the website's content from its form. The content & metadata of your website are in structured markdown files, while various other files constitute the theme, specifying how to transform that content & metadata into HTML pages. You keep these various markdown (.md), YAML (.yml), HTML, and CSS files in a public GitHub repository. Each time you commit and push an update to the repository, the [GitHub pages](https://pages.github.com/) service creates static HTML pages based on these files, which are hosted on GitHub's servers free of charge.

Many of the features of dynamic content management systems (like Wordpress) can be achieved in this fashion, using a fraction of the computational resources and with far less vulnerability to hacking and DDoSing. You can also modify the theme to your heart's content without touching the content of your site. If you get to a point where you've broken something in Jekyll/HTML/CSS beyond repair, your markdown files describing your talks, publications, etc. are safe. You can rollback the changes or even delete the repository and start over -- just be sure to save the markdown files! Finally, you can also write scripts that process the structured data on the site, such as [this one](https://github.com/academicpages/academicpages.github.io/blob/master/talkmap.ipynb) that analyzes metadata in pages about talks to display [a map of every location you've given a talk](https://academicpages.github.io/talkmap.html). -->

<!-- Getting started
======
1. Register a GitHub account if you don't have one and confirm your e-mail (required!)
1. Fork [this repository](https://github.com/academicpages/academicpages.github.io) by clicking the "fork" button in the top right. 
1. Go to the repository's settings (rightmost item in the tabs that start with "Code", should be below "Unwatch"). Rename the repository "[your GitHub username].github.io", which will also be your website's URL.
1. Set site-wide configuration and create content & metadata (see below -- also see [this set of diffs](http://archive.is/3TPas) showing what files were changed to set up [an example site](https://getorg-testacct.github.io) for a user with the username "getorg-testacct")
1. Upload any files (like PDFs, .zip files, etc.) to the files/ directory. They will appear at https://[your GitHub username].github.io/files/example.pdf.  
1. Check status by going to the repository settings, in the "GitHub pages" section

Site-wide configuration
------
The main configuration file for the site is in the base directory in [_config.yml](https://github.com/academicpages/academicpages.github.io/blob/master/_config.yml), which defines the content in the sidebars and other site-wide features. You will need to replace the default variables with ones about yourself and your site's github repository. The configuration file for the top menu is in [_data/navigation.yml](https://github.com/academicpages/academicpages.github.io/blob/master/_data/navigation.yml). For example, if you don't have a portfolio or blog posts, you can remove those items from that navigation.yml file to remove them from the header. 

Create content & metadata
------
For site content, there is one markdown file for each type of content, which are stored in directories like _publications, _talks, _posts, _teaching, or _pages. For example, each talk is a markdown file in the [_talks directory](https://github.com/academicpages/academicpages.github.io/tree/master/_talks). At the top of each markdown file is structured data in YAML about the talk, which the theme will parse to do lots of cool stuff. The same structured data about a talk is used to generate the list of talks on the [Talks page](https://academicpages.github.io/talks), each [individual page](https://academicpages.github.io/talks/2012-03-01-talk-1) for specific talks, the talks section for the [CV page](https://academicpages.github.io/cv), and the [map of places you've given a talk](https://academicpages.github.io/talkmap.html) (if you run this [python file](https://github.com/academicpages/academicpages.github.io/blob/master/talkmap.py) or [Jupyter notebook](https://github.com/academicpages/academicpages.github.io/blob/master/talkmap.ipynb), which creates the HTML for the map based on the contents of the _talks directory).

**Markdown generator**

I have also created [a set of Jupyter notebooks](https://github.com/academicpages/academicpages.github.io/tree/master/markdown_generator
) that converts a CSV containing structured data about talks or presentations into individual markdown files that will be properly formatted for the academicpages template. The sample CSVs in that directory are the ones I used to create my own personal website at stuartgeiger.com. My usual workflow is that I keep a spreadsheet of my publications and talks, then run the code in these notebooks to generate the markdown files, then commit and push them to the GitHub repository.

How to edit your site's GitHub repository
------
Many people use a git client to create files on their local computer and then push them to GitHub's servers. If you are not familiar with git, you can directly edit these configuration and markdown files directly in the github.com interface. Navigate to a file (like [this one](https://github.com/academicpages/academicpages.github.io/blob/master/_talks/2012-03-01-talk-1.md) and click the pencil icon in the top right of the content preview (to the right of the "Raw | Blame | History" buttons). You can delete a file by clicking the trashcan icon to the right of the pencil icon. You can also create new files or upload files by navigating to a directory and clicking the "Create new file" or "Upload files" buttons. 

Example: editing a markdown file for a talk
![Editing a markdown file for a talk](/images/editing-talk.png)

For more info
------
More info about configuring academicpages can be found in [the guide](https://academicpages.github.io/markdown/). The [guides for the Minimal Mistakes theme](https://mmistakes.github.io/minimal-mistakes/docs/configuration/) (which this theme was forked from) might also be helpful. -->
